{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modeling with NMF and SVD\n",
    "\n",
    "Link to the [YouTube video for this notebook](https://www.youtube.com/watch?v=tG3pUwmGjsc&list=PLtmWHNX-gukKocXQOkQjuVxglSDYWsSh9&index=18&t=0s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Topic modeling is a fun way to start our study of NLP. We will use two popular **matrix decomposition techniques**. \n",
    "Non-Negative Matrix Fatactorization (NMF) and Singular Value Decomposition (SVD).\n",
    "\n",
    "\n",
    "\n",
    "We start with a **term-document matrix**:\n",
    "\n",
    "\n",
    "<img src=\"images/document_term.png\" alt=\"term-document matrix\" style=\"width: 70%\"/>\n",
    "\n",
    "source: [Introduction to Information Retrieval](http://player.slideplayer.com/15/4528582/#)\n",
    "\n",
    "This is a representation of the plays of Shakespare. Notice that this representation does not take into account word order or sentence structure.  It's an example of a **bag of words** approach.\n",
    "\n",
    "We can decompose this into one tall thin matrix times one wide short matrix (possibly with a diagonal matrix in between). The idea of decomposition is that you break up the larger matrix into smaller products of matrices, where the matrices are multiplied together to give you the orignal matrix. The reason this is useful is that the separate factors are a lot nicer to deal with than the original matrix. THis is called  Latent Semantic Analysis (LSA) and it uses Singular Value Decomposition (SVD).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Motivation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the most extreme case - reconstructing the matrix using an outer product of two vectors. Clearly, in most cases we won't be able to reconstruct the matrix exactly. But if we had one vector with the relative frequency of each vocabulary word out of the total word count, and one with the average number of words per document, then that outer product would be as close as we can get.\n",
    "\n",
    "Now consider increasing that matrices to two columns and two rows. The optimal decomposition would now be to cluster the documents into two groups, each of which has as different a distribution of words as possible to each other, but as similar as possible amongst the documents in the cluster. We will call those two groups \"topics\". And we would cluster the words into two groups, based on those which most frequently appear in each of the topics. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll take a dataset of documents in several different categories, and find topics (consisting of groups of words) for them.  Knowing the actual categories helps us evaluate if the topics we find make sense.\n",
    "\n",
    "We will try this with two different matrix factorizations: **Singular Value Decomposition (SVD)** and **Non-negative Matrix Factorization (NMF)** and use the 20 News Groups dataset that comes with scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn import decomposition\n",
    "from scipy import linalg\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional Resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Data source](http://scikit-learn.org/stable/datasets/twenty_newsgroups.html): Newsgroups are discussion groups on Usenet, which was popular in the 80s and 90s before the web really took off.  This dataset includes 18,000 newsgroups posts with 20 topics.\n",
    "- [Chris Manning's book chapter](https://nlp.stanford.edu/IR-book/pdf/18lsi.pdf) on matrix factorization and LSI \n",
    "- Scikit learn [truncated SVD LSI details](http://scikit-learn.org/stable/modules/decomposition.html#lsa)\n",
    "\n",
    "### Other Tutorials\n",
    "- [Scikit-Learn: Out-of-core classification of text documents](http://scikit-learn.org/stable/auto_examples/applications/plot_out_of_core_classification.html): uses [Reuters-21578](https://archive.ics.uci.edu/ml/datasets/reuters-21578+text+categorization+collection) dataset (Reuters articles labeled with ~100 categories), HashingVectorizer\n",
    "- [Text Analysis with Topic Models for the Humanities and Social Sciences](https://de.dariah.eu/tatom/index.html): uses [British and French Literature dataset](https://de.dariah.eu/tatom/datasets.html) of Jane Austen, Charlotte Bronte, Victor Hugo, and more"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at our data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit Learn comes with a number of [built-in datasets](https://scikit-learn.org/stable/datasets/), as well as loading utilities to load several standard external datasets. Datasets include Boston housing prices, face images, patches of forest, diabetes, breast cancer, and more.  We will be using the [newsgroups](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_20newsgroups.html#sklearn.datasets.fetch_20newsgroups) dataset. Note there are two versions of how you can load this dataset, the second is [vectorised newsgroups](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_20newsgroups_vectorized.html#sklearn.datasets.fetch_20newsgroups_vectorized) where the data is loaded and vetorised using token counts.\n",
    "\n",
    "#### What are Newsgroups?\n",
    "\n",
    "Newsgroups are discussion groups on [Usenet](https://en.wikipedia.org/wiki/Usenet_newsgroup), which was popular in the 80s and 90s before the web really took off. The 20 newsgroups dataset comprises around 18,000 newsgroups posts on 20 topics split in two subsets: one for training (or development) and the other one for testing (or for performance evaluation). The split between the train and test set is based upon a messages posted before and after a specific date. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc']\n"
     ]
    }
   ],
   "source": [
    "# Loads the entire dataset and returns the raw text as a list\n",
    "newsgroups_all = fetch_20newsgroups()  \n",
    "\n",
    "# To see the list of categories\n",
    "print(list(newsgroups_all.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Take a quick look at the entire dataset \n",
    "#newsgroups_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Topic modelling is an unsupervised problem in that you don't know what the right answer is –– what are the best topics for my documents? Typically you don't have a set of right answers. To make life simpler we can just pick a few categories. This helps to figure out if we're doing ok. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also load pre-defined train and test sets with shuffled ordering. \n",
    "# In this case we'll also just choose four categories and we'll remove headers, footers, and quotes.\n",
    "categories = ['alt.atheism', 'talk.religion.misc', 'comp.graphics', 'sci.space']\n",
    "remove = ('headers', 'footers', 'quotes')\n",
    "\n",
    "newsgroups_train = fetch_20newsgroups(subset='train', categories=categories, remove=remove)\n",
    "newsgroups_test = fetch_20newsgroups(subset='test', categories=categories, remove=remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2034,), (2034,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2034 posts in the training set\n",
    "newsgroups_train.filenames.shape, newsgroups_train.target.shape  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Hi,\\n\\nI've noticed that if you only save a model (with all your mapping planes\\npositioned carefully) to a .3DS file that when you reload it after restarting\\n3DS, they are given a default position and orientation.  But if you save\\nto a .PRJ file their positions/orientation are preserved.  Does anyone\\nknow why this information is not stored in the .3DS file?  Nothing is\\nexplicitly said in the manual about saving texture rules in the .PRJ file. \\nI'd like to be able to read the texture rule information, does anyone have \\nthe format for the .PRJ file?\\n\\nIs the .CEL file format available from somewhere?\\n\\nRych\"]\n"
     ]
    }
   ],
   "source": [
    "# This is what the raw text looks like:\n",
    "print(newsgroups_train.data[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi,\n",
      "\n",
      "I've noticed that if you only save a model (with all your mapping planes\n",
      "positioned carefully) to a .3DS file that when you reload it after restarting\n",
      "3DS, they are given a default position and orientation.  But if you save\n",
      "to a .PRJ file their positions/orientation are preserved.  Does anyone\n",
      "know why this information is not stored in the .3DS file?  Nothing is\n",
      "explicitly said in the manual about saving texture rules in the .PRJ file. \n",
      "I'd like to be able to read the texture rule information, does anyone have \n",
      "the format for the .PRJ file?\n",
      "\n",
      "Is the .CEL file format available from somewhere?\n",
      "\n",
      "Rych\n"
     ]
    }
   ],
   "source": [
    "# And in this case we're printing a represenation where the strings \\n are joined by a new line\n",
    "# It's just a nicer way to view each post\n",
    "print(\"\\n\".join(newsgroups_train.data[:1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Can you guess which category these message is in?**  \n",
    "Probably `computer graphics`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " >In article <1993Apr19.020359.26996@sq.sq.com>, msb@sq.sq.com (Mark Brader) \n",
      "\n",
      "MB>                                                             So the\n",
      "MB> 1970 figure seems unlikely to actually be anything but a perijove.\n",
      "\n",
      "JG>Sorry, _perijoves_...I'm not used to talking this language.\n",
      "\n",
      "Couldn't we just say periapsis or apoapsis?\n",
      "\n",
      " \n"
     ]
    }
   ],
   "source": [
    "# Let's look at another one\n",
    "print(\"\\n\".join(newsgroups_train.data[2:3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What about this?**  \n",
    "hint: definition of *perijove* is the point in the orbit of a satellite of Jupiter nearest the planet's center. \n",
    "\n",
    "This message probably belongs to `space`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['comp.graphics', 'talk.religion.misc', 'sci.space'], dtype='<U18')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can turn the category list into a numpy array and look at the target categories for those first three message:\n",
    "np.array(newsgroups_train.target_names)[newsgroups_train.target[:3]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The target attribute is the integer index of the category. These are our target labels or out `y` in the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 3, 2, 0, 2, 0, 2, 1, 2, 1])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsgroups_train.target[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For most clusetring analyses (e.g. K-means) you have to choose how many topics (or clusters) you want to look for. Most of the time you really don't know this so as a first pass it's ok to take an educated guess. (e.g. we know there will be less than 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we'll see if we can find 6 clusters, but really this could be anything. There is no ground truth.\n",
    "num_topics, num_top_words = 6, 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An aside: Stop words, stemming, lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From [Intro to Information Retrieval](https://nlp.stanford.edu/IR-book/html/htmledition/dropping-common-terms-stop-words-1.html):\n",
    "\n",
    "*Some extremely common words which would appear to be of little value in helping select documents matching a user need are excluded from the vocabulary entirely. These words are called stop words.*\n",
    "\n",
    "*The general trend in IR systems over time has been from standard use of quite large stop lists (200-300 terms) to very small stop lists (7-12 terms) to no stop list whatsoever. Web search engines generally do not use stop lists.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scikit NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'across',\n",
       " 'after',\n",
       " 'afterwards',\n",
       " 'again',\n",
       " 'against',\n",
       " 'all',\n",
       " 'almost',\n",
       " 'alone',\n",
       " 'along',\n",
       " 'already',\n",
       " 'also',\n",
       " 'although',\n",
       " 'always',\n",
       " 'am',\n",
       " 'among',\n",
       " 'amongst',\n",
       " 'amoungst']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# There is no single universal list of stop words. But these are the first 20 from NLTK's\n",
    "# However these words would be useful in language modelling\n",
    "\n",
    "from sklearn.feature_extraction import stop_words\n",
    "\n",
    "sorted(list(stop_words.ENGLISH_STOP_WORDS))[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemming and Lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from [Information Retrieval](https://nlp.stanford.edu/IR-book/html/htmledition/stemming-and-lemmatization-1.html) textbook:\n",
    "\n",
    "Are the below words the same?\n",
    "\n",
    "- *organize, organizes, and organizing*\n",
    "- *democracy, democratic, and democratization*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stemming and Lemmatization both generate the root form of the words. \n",
    "\n",
    "Lemmatization uses the rules about a language.  The resulting tokens are all actual words\n",
    "\n",
    "\"Stemming is the poor-man’s lemmatization.\" (Noah Smith, 2011) Stemming is a crude heuristic that chops the ends off of words.  The resulting tokens may not be actual words. The upside is that stemming is faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# NLTK version: 3.4.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/akarick/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "print('# NLTK version:', nltk.__version__)\n",
    "\n",
    "# nltk.download('wordnet')  # Already up to date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "wnl = stem.WordNetLemmatizer()\n",
    "porter = stem.porter.PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list1 = ['feet', 'foot', 'foots', 'footing']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['foot', 'foot', 'foot', 'footing']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## You could define a function beginning with 'for word in word_list'... or you can do this\"\n",
    "[wnl.lemmatize(word) for word in word_list1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['feet', 'foot', 'foot', 'foot']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[porter.stem(word) for word in word_list1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your turn!  Now, try lemmatizing and stemming the following collections of words:\n",
    "\n",
    "- fly, flies, flying\n",
    "- organize, organizes, organizing\n",
    "- universe, university"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fly', 'fly', 'flying']"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_list2 = ['fly', 'flies', 'flying']\n",
    "[wnl.lemmatize(word) for word in word_list2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fli', 'fli', 'fli']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[porter.stem(word) for word in word_list2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['organize', 'organizes', 'organizing']"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_list3 = ['organize','organizes','organizing']\n",
    "[wnl.lemmatize(word) for word in word_list3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['organ', 'organ', 'organ']"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NOTE: In this case stemming results in a word that has a completely different meaning\n",
    "# Also - English vs US spelling metters\n",
    "[porter.stem(word) for word in word_list3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['universe', 'university']"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_list4 = ['universe', 'university']\n",
    "[wnl.lemmatize(word) for word in word_list4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['univers', 'univers']"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NOTE: In this case universe and university are completely different but stem to the same word\n",
    "[porter.stem(word) for word in word_list4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stemming and lemmatization are language dependent.  Languages with more complex morphologies may show bigger benefits.  For example, Sanskrit has a very [large number of verb forms](https://en.wikipedia.org/wiki/Sanskrit_verbs). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stemming and lemmatization are implementation dependent.\n",
    "\n",
    "Spacy documentation: https://spacy.io/usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spacy is a very modern & fast nlp library. Spacy is opinionated, in that it typically offers one highly optimized way to do something (whereas NLTK offers a huge variety of ways, although they are usually not as optimized).\n",
    "\n",
    "You will need to install it.\n",
    "\n",
    "if you use conda:\n",
    "```\n",
    "conda install -c conda-forge spacy      # command line terminal - OR\n",
    "\n",
    "pip install -U spacy\n",
    "```\n",
    "\n",
    "You will then need to download the English model. It includes the language data, as well as binary weight to enable spaCy to make predictions for part-of-speech tags, dependencies and named entities.\n",
    "```\n",
    "python -m spacy download en_core_web_sm   # command line terminal\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Spacy version: 2.1.8\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import en_core_web_sm\n",
    "\n",
    "print('# Spacy version:', spacy.__version__)\n",
    "\n",
    "#The language data shipped with spaCy includes the static data like tokenization rules, stop words or lemmatization tables.\n",
    "from spacy.lang.en import English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.lemmatizer import Lemmatizer\n",
    "lemmatizer = Lemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['feet', 'foot', 'foots', 'footing']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[lemmatizer.lookup(word) for word in word_list1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spacy doesn't offer a stemmer since lemmatization is considered better --- *an example of being opinionated*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stop words also vary from library to library. The Spacy stop  words are different to the scikit-learn stop workds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"'d\",\n",
       " \"'ll\",\n",
       " \"'m\",\n",
       " \"'re\",\n",
       " \"'s\",\n",
       " \"'ve\",\n",
       " 'a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'across',\n",
       " 'after',\n",
       " 'afterwards',\n",
       " 'again',\n",
       " 'against',\n",
       " 'all',\n",
       " 'almost',\n",
       " 'alone',\n",
       " 'along',\n",
       " 'already',\n",
       " 'also']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Spacy stop words (note this may also be version dependent) \n",
    "\n",
    "sorted(list(nlp.Defaults.stop_words))[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise: What stop words appear in spacy but not in sklearn?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\"'d\",\n",
       " \"'ll\",\n",
       " \"'m\",\n",
       " \"'re\",\n",
       " \"'s\",\n",
       " \"'ve\",\n",
       " 'ca',\n",
       " 'did',\n",
       " 'does',\n",
       " 'doing',\n",
       " 'just',\n",
       " 'make',\n",
       " \"n't\",\n",
       " 'n‘t',\n",
       " 'n’t',\n",
       " 'quite',\n",
       " 'really',\n",
       " 'regarding',\n",
       " 'say',\n",
       " 'unless',\n",
       " 'used',\n",
       " 'using',\n",
       " 'various',\n",
       " '‘d',\n",
       " '‘ll',\n",
       " '‘m',\n",
       " '‘re',\n",
       " '‘s',\n",
       " '‘ve',\n",
       " '’d',\n",
       " '’ll',\n",
       " '’m',\n",
       " '’re',\n",
       " '’s',\n",
       " '’ve'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.Defaults.stop_words - stop_words.ENGLISH_STOP_WORDS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Exercise: And what stop words are in sklearn but not spacy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "frozenset({'amoungst',\n",
       "           'bill',\n",
       "           'cant',\n",
       "           'co',\n",
       "           'con',\n",
       "           'couldnt',\n",
       "           'cry',\n",
       "           'de',\n",
       "           'describe',\n",
       "           'detail',\n",
       "           'eg',\n",
       "           'etc',\n",
       "           'fill',\n",
       "           'find',\n",
       "           'fire',\n",
       "           'found',\n",
       "           'hasnt',\n",
       "           'ie',\n",
       "           'inc',\n",
       "           'interest',\n",
       "           'ltd',\n",
       "           'mill',\n",
       "           'sincere',\n",
       "           'system',\n",
       "           'thick',\n",
       "           'thin',\n",
       "           'un'})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words.ENGLISH_STOP_WORDS - nlp.Defaults.stop_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### When to use these?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<img src=\"images/skomoroch.png\" alt=\"\" style=\"width: 65%\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "These were long considered standard techniques, but they can often **hurt** your performance **if using deep learning**. Stemming, lemmatization, and removing stop words all involve throwing away information.\n",
    "\n",
    "However, they can still be useful when working with simpler models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Another approach: sub-word units"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "[SentencePiece](https://github.com/google/sentencepiece) library from Google"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing (Using NLTK)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, scikit learn has a method that will extract all the word counts for us.  In the next lesson, we'll learn how to write our own version of CountVectorizer, to see what's happening underneath the hood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/akarick/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "#nltk.download('punkt')  # already up to date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from nltk import word_tokenize\n",
    "\n",
    "# class LemmaTokenizer(object):\n",
    "#     def __init__(self):\n",
    "#         self.wnl = stem.WordNetLemmatizer()\n",
    "#     def __call__(self, doc):\n",
    "#         return [self.wnl.lemmatize(t) for t in word_tokenize(doc)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(stop_words='english') #, tokenizer=LemmaTokenizer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2034, 26576)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## From the 2034 we get 26,576 words or tokens\n",
    "# This is our Term Document matrix and we'll call it 'vectors'\n",
    "\n",
    "vectors = vectorizer.fit_transform(newsgroups_train.data).todense() # (documents, vocab)\n",
    "vectors.shape #, vectors.nnz / vectors.shape[0], row_means.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2034 (2034, 26576)\n"
     ]
    }
   ],
   "source": [
    "print(len(newsgroups_train.data), vectors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = np.array(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26576,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['cosmonauts', 'cosmos', 'cosponsored', 'cost', 'costa', 'costar',\n",
       "       'costing', 'costly', 'costruction', 'costs', 'cosy', 'cote',\n",
       "       'couched', 'couldn', 'council', 'councils', 'counsel',\n",
       "       'counselees', 'counselor', 'count'], dtype='<U80')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab[7000:7020]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**An example of where we are going with this:**\n",
    "\n",
    "Imagine you have a document matrix of authors and their books (e.g. Austen, Dickens) and vocab words\n",
    "\n",
    "Term Document matrix A (data matrix): AUTHOR_TITLE vs. VOCAB_WORDS  (Normalised by TF_IDF) \n",
    "\n",
    "SVD matrix decomposition gives you three matrices: U, S, Vh\n",
    "\n",
    "U: AUTHOR_TITLE (documents) vs. TOPIC  (left singular vectors)  \n",
    "S: TOPIC vs. TOPIC  (&Sigma; or diagonal of singular values in the diagram below)  \n",
    "Vh: TOPC vs. VOCAB_WORDS  (right singular vectors)  \n",
    "\n",
    "\n",
    "The vectors are orthonormal. What does this mean?  \n",
    "Orthogonal (the dot product of two matrices = 0) and their magnitues are 1.0 (the dot product of a matrix with itself = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Singular Value Decomposition (SVD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"SVD is not nearly as famous as it should be.\" - Gilbert Strang"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would clearly expect that the words that appear most frequently in one topic would appear less frequently in the other - otherwise that word wouldn't make a good choice to separate out the two topics. Therefore, we expect the topics to be **orthogonal**.\n",
    "\n",
    "The SVD algorithm factorizes a matrix into one matrix with **orthogonal columns** and one with **orthogonal rows** (along with a diagonal matrix, which contains the **relative importance** of each factor).\n",
    "\n",
    "<img src=\"images/svd_fb.png\" alt=\"\" style=\"width: 80%\"/>\n",
    "(source: [Facebook Research: Fast Randomized SVD](https://research.fb.com/fast-randomized-svd/))\n",
    "\n",
    "SVD is an **exact decomposition**, since the matrices it creates are big enough to fully cover the original matrix.  \n",
    "SVD is extremely widely used in linear algebra, and specifically in data science, including:\n",
    "\n",
    "- semantic analysis (e.g. topic modelling) \n",
    "- collaborative filtering/recommendations ([winning entry for Netflix Prize](https://datajobs.com/data-science-repo/Recommender-Systems-%5BNetflix%5D.pdf))\n",
    "- calculate Moore-Penrose pseudoinverse\n",
    "- data compression\n",
    "- principal component analysis\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Latent Semantic Analysis (LSA) uses SVD.  You will sometimes hear topic modelling referred to as LSA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 36.8 s, sys: 2.06 s, total: 38.9 s\n",
      "Wall time: 12.5 s\n"
     ]
    }
   ],
   "source": [
    "## vectors here is the Term Document Matrix\n",
    "\n",
    "%time U, s, Vh = linalg.svd(vectors, full_matrices=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2034, 2034) (2034,) (2034, 26576)\n"
     ]
    }
   ],
   "source": [
    "print(U.shape, s.shape, Vh.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confirm this is a decomposition of the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([433.92698542, 291.51012741, 240.71137677, 220.00048043])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Note that while s is a matrix it's actually a 1D array\n",
    "s[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[433.92698542,   0.        ,   0.        ,   0.        ],\n",
       "       [  0.        , 291.51012741,   0.        ,   0.        ],\n",
       "       [  0.        ,   0.        , 240.71137677,   0.        ],\n",
       "       [  0.        ,   0.        ,   0.        , 220.00048043]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If we apply np.diag() we get back the matrix\n",
    "np.diag(s[:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([433.92698542, 291.51012741, 240.71137677, 220.00048043])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Do it again and we get the 1D array \n",
    "np.diag(np.diag(s[:4]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exercise: confirm that U, s, Vh is a decomposition of `vectors`\n",
    "# Note that we convert s to a matrix\n",
    "\n",
    "reconstructed_vectors = U @ np.diag(s) @ Vh    \n",
    "np.allclose(reconstructed_vectors, vectors)\n",
    "\n",
    "# Alternate way of doing the above:\n",
    "# np.linalg.norm(reconstructed_vectors - vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A note about `np.allclose`\n",
    "\n",
    "Returns True if two arrays are element-wise equal within a tolerance: https://docs.scipy.org/doc/numpy/reference/generated/numpy.allclose.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Excercise: Confirm that U, V are orthonormal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Exercise: Confirm that U, Vh are orthonormal -- this means the dot product of two matrices= 0\n",
    "np.allclose = U.T @ U, np.eye(U.shape[0])\n",
    "np.allclose = Vh @ Vh.T, np.eye(Vh.shape[0])\n",
    "\n",
    "# If you took the alternate example above, you would be checking that the difference is zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "What can we say about the singular values s?\n",
    "\n",
    "They are non-negative and decreasing quickly.\n",
    "This is telling you something about the importance of the topics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(s);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1a2bc7b860>]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(s[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## Now let's look at the most frequent top words for each topics\n",
    "## Remember each topic includes a little bit of each word in the vocabulary\n",
    "\n",
    "num_top_words=8\n",
    "\n",
    "def show_topics(a):\n",
    "    top_words = lambda t: [vocab[i] for i in np.argsort(t)[:-num_top_words-1:-1]]\n",
    "    topic_words = ([top_words(t) for t in a])\n",
    "    return [' '.join(t) for t in topic_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ditto critus propagandist surname galacticentric kindergarten surreal imaginative',\n",
       " 'jpeg gif file color quality image jfif format',\n",
       " 'graphics edu pub mail 128 3d ray ftp',\n",
       " 'jesus god matthew people atheists atheism does graphics',\n",
       " 'image data processing analysis software available tools display',\n",
       " 'god atheists atheism religious believe religion argument true',\n",
       " 'space nasa lunar mars probe moon missions probes',\n",
       " 'image probe surface lunar mars probes moon orbit',\n",
       " 'argument fallacy conclusion example true ad argumentum premises',\n",
       " 'space larson image theory universe physical nasa material']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_topics(Vh[:10])    \n",
    "\n",
    "## apparently this is actually using 2000 topics not the 6 clusters we chose. \n",
    "## Not quite sure why but apparently it will be explained later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The first one doesn't seem to map to a topic, but the second one seems to map to `computer graphics`.  \n",
    "The fourth looks like it's mapping to `religion` or `atheism`.\n",
    "\n",
    "Note that they are not definitive, but they do make sense... mostly.\n",
    "\n",
    "We get topics that match the kinds of clusters we would expect! This is despite the fact that this is an **unsupervised algorithm** - which is to say, we never actually told the algorithm how our documents are grouped."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We will return to SVD in **much more detail** later.  For now, the important takeaway is that we have a tool that allows us to exactly factor a matrix into orthogonal columns and orthogonal rows.\n",
    "\n",
    "Another thing to note is that SVD can result in negative values and this can make it hard to interpret. NMF as the name implies in non-negative and may be easier to interpret."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-negative Matrix Factorization (NMF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Motivation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/face_pca.png\" alt=\"PCA on faces\" style=\"width: 80%\"/>\n",
    "\n",
    "(source: [NMF Tutorial](http://perso.telecom-paristech.fr/~essid/teach/NMF_tutorial_ICME-2014.pdf))\n",
    "\n",
    "A more interpretable approach:\n",
    "\n",
    "<img src=\"images/face_outputs.png\" alt=\"NMF on Faces\" style=\"width: 80%\"/>\n",
    "\n",
    "(source: [NMF Tutorial](http://perso.telecom-paristech.fr/~essid/teach/NMF_tutorial_ICME-2014.pdf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Idea"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rather than constraining our factors to be *orthogonal*, another idea would to constrain them to be *non-negative*. NMF is a factorization of a non-negative data set $V$: $$ V = W H$$ into non-negative matrices $W,\\; H$. Often positive factors will be **more easily interpretable** (and this is the reason behind NMF's popularity). \n",
    "\n",
    "<img src=\"images/face_nmf.png\" alt=\"NMF on faces\" style=\"width: 80%\"/>\n",
    "\n",
    "(source: [NMF Tutorial](http://perso.telecom-paristech.fr/~essid/teach/NMF_tutorial_ICME-2014.pdf))\n",
    "\n",
    "Nonnegative matrix factorization (NMF) is a non-exact factorization that factors into one skinny positive matrix and one short positive matrix.  NMF is NP-hard and non-unique (unlike SVD).  There are a number of variations on it, created by adding different constraints. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Applications of NMF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Face Decompositions](http://scikit-learn.org/stable/auto_examples/decomposition/plot_faces_decomposition.html#sphx-glr-auto-examples-decomposition-plot-faces-decomposition-py)\n",
    "- [Collaborative Filtering, eg movie recommendations](http://www.quuxlabs.com/blog/2010/09/matrix-factorization-a-simple-tutorial-and-implementation-in-python/)\n",
    "- [Audio source separation](https://pdfs.semanticscholar.org/cc88/0b24791349df39c5d9b8c352911a0417df34.pdf)\n",
    "- [Chemistry](http://ieeexplore.ieee.org/document/1532909/)\n",
    "- [Bioinformatics](https://bmcbioinformatics.biomedcentral.com/articles/10.1186/s12859-015-0485-4) and [Gene Expression](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2623306/)\n",
    "- Topic Modeling (our problem!)\n",
    "\n",
    "<img src=\"images/nmf_doc.png\" alt=\"NMF on documents\" style=\"width: 80%\"/>\n",
    "\n",
    "(source: [NMF Tutorial](http://perso.telecom-paristech.fr/~essid/teach/NMF_tutorial_ICME-2014.pdf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**More Reading**:\n",
    "\n",
    "- [The Why and How of Nonnegative Matrix Factorization](https://arxiv.org/pdf/1401.5226.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NMF from sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use [scikit-learn's implementation of NMF](http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.NMF.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "m,n=vectors.shape\n",
    "d=5  # number topics is a hyperparameter \n",
    "\n",
    "# Nnlike k-means you can't find a way to optimise k – this is a little unsatisfying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = decomposition.NMF(n_components=d, random_state=1)\n",
    "\n",
    "W1 = clf.fit_transform(vectors)\n",
    "H1 = clf.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['jpeg image gif file color images format quality',\n",
       " 'edu graphics pub mail 128 ray ftp send',\n",
       " 'space launch satellite nasa commercial satellites year market',\n",
       " 'jesus god people matthew atheists does atheism said',\n",
       " 'image data available software processing ftp edu analysis']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_topics(H1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again we get `computer graphics`, `space`, `religion` or `athiesm`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Topic Frequency-Inverse Document Frequency](http://www.tfidf.com/) (TF-IDF) is a way to normalize term counts by taking into account how often they appear in a document, how long the document is, and how commmon/rare the term is.\n",
    "\n",
    "TF = (# occurrences of term t in document) / (# of words in documents)\n",
    "\n",
    "IDF = log(# of documents / # documents with term t in it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer_tfidf = TfidfVectorizer(stop_words='english')\n",
    "vectors_tfidf = vectorizer_tfidf.fit_transform(newsgroups_train.data) # (documents, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"a\\n\\nWhat about positional uncertainties in S-L 1993e?   I assume we know where\\nand what Galileo is doing within a few meters.   But without the\\nHGA,  don't we have to have some pretty good ideas, of where to look\\nbefore imaging?  If the HGA was working,  they could slew around\\nin near real time (Less speed of light delay).  But when they were\\nimaging toutatis????  didn't someone have to get lucky on a guess to\\nfind the first images?   \\n\\nAlso, I imagine S-L 1993e will be mostly a visual image.  so how will\\nthat affect the other imaging missions.  with the LGA,  there is a real\\ntight allocation of bandwidth.   It may be premature to hope for answers,\\nbut I thought i'd throw it on the floor.\",\n",
       " \"I would like to program Tseng ET4000 to nonstandard 1024x768 mode by\\nswitching to standard 1024x768 mode using BIOS and than changing some\\ntiming details (0x3D4 registers 0x00-0x1F) but I don't know how to\\nselect 36 MHz pixel clock I need. The BIOS function selects 40 MHz.\\n\\nIs there anybody who knows where to obtain technical info about this.\\nI am also interested in any other technical information about Tseng ET4000\\nand Trident 8900 and 9000 chipsets.\\n\\n\\t\\t\\tthanks very much\",\n",
       " 'In-Reply-To: <20APR199312262902@rigel.tamu.edu> lmp8913@rigel.tamu.edu (PRESTON, LISA M)',\n",
       " \"\\n\\n\\n\\nI'm not sure, but it almost sounds like they can't figure out where the \\n_nucleus_ is within the coma. If they're off by a couple hundred\\nmiles, well, you can imagine the rest...\\n\",\n",
       " \"Hello,\\n     I am looking to add voice input capability to a user interface I am\\ndeveloping on an HP730 (UNIX) workstation.  I would greatly appreciate \\ninformation anyone would care to offer about voice input systems that are \\neasily accessible from the UNIX environment. \\n\\n     The names or adresses of applicable vendors, as well as any \\nexperiences you have had with specific systems, would be very helpful.\\n\\n     Please respond via email; I will post a summary if there is \\nsufficient interest.\\n\\n\\nThanks,\\nKen\\n\\n\\nP.S.  I have found several impressive systems for IBM PC's, but I would \\nlike to avoid the hassle of purchasing and maintaining a separate PC if \\nat all possible.\\n\\n-------------------------------------------------------------------------------\\nKen Hinckley (kph2q@virginia.edu)\\nUniversity of Virginia \\nNeurosurgical Visualization Laboratory\"]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsgroups_train.data[10:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "W1 = clf.fit_transform(vectors_tfidf)\n",
    "H1 = clf.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['people don think just like objective say morality',\n",
       " 'graphics thanks files image file program windows know',\n",
       " 'space nasa launch shuttle orbit moon lunar earth',\n",
       " 'ico bobbe tek beauchaine bronx manhattan sank queens',\n",
       " 'god jesus bible believe christian atheism does belief']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_topics(H1)\n",
    "\n",
    "# Note the fourth one is pretty weird but third looks good "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f15cb8ae0f0>]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzt3XuUFOWdN/DvTwzmrDFvNJDdHG8Yl2yWbBJNJsYkm2zuYi4QcxNzWc2a9U1OOMm+STaLGolBE42JJlExKwrGaBQxRkBAERCVi8AMtwFmGGYYbsMAM8AwA8y1Z37vH1091PRUdT9VXdXVVf39nMOhu7qm+nm6qn711FPPRVQVRESULKdFnQAiIgoegzsRUQIxuBMRJRCDOxFRAjG4ExElEIM7EVECMbgTESUQgzsRUQIxuBMRJdDpUX3xqFGjdMyYMVF9PRFRLK1fv/6wqo7Ot15kwX3MmDGoqqqK6uuJiGJJRPaYrMdqGSKiBGJwJyJKIAZ3IqIEYnAnIkogBnciogRicCciSiAGdyKiBDIK7iIyXkTqRKRBRKa4rPM1EakRkW0i8kSwySSiQm3c24at+9ujTgYVSd5OTCIyAsB0AJ8G0ASgUkTmq2qNbZ2xAG4E8GFVbRORt4SVYCLy56oHVgMAdt/5uYhTQsVgUnK/DECDqjaqai+A2QAmZq3znwCmq2obAKhqS7DJJCIiL0yC+7kA9tneN1nL7N4O4O0iskpE1ojIeKcNicgNIlIlIlWtra3+UkxERHmZBHdxWKZZ708HMBbAxwBcA+BhEXnTsD9SnaGqFapaMXp03nFviIjIJ5Pg3gTgfNv78wA0O6wzT1X7VHUXgDqkgz0llKrit4vrsPvwyaiTQkQOTIJ7JYCxInKRiIwEMAnA/Kx15gL4OACIyCikq2kag0wolZamti7cv7wB3/5TZdRJISIHeYO7qqYATAawGEAtgDmquk1EponIBGu1xQCOiEgNgOUA/ltVj4SVaCodff0DUSeBiBwYjeeuqosALMpaNtX2WgH8yPpHREQRYw9VIqIEYnAnorIzMKDo6O6LOhmhYnAnorLzu6U78O5bX0Tbyd6okxIaBnciKjsLqw8AAI52MrgTEVGMMLgTESUQgzsRUQIxuBMRJRCDOxFRAjG4ExElEIM7EVECMbgTESUQgzsRlS3NnnYoQRjciaj8OM0vlzAM7kRECcTgTuTB1v3t0CTfy1NiMLgTGXp1Rys+f99KPL5mT9RJIcqLwZ3I0J6jnQCA7QePR5wSovwY3ImIEojBnYgogRjciYgSiMGdiCiBGNyJiBLIKLiLyHgRqRORBhGZ4vD5dSLSKiKbrH/fCT6pRERk6vR8K4jICADTAXwaQBOAShGZr6o1Was+paqTQ0gjERF5ZFJyvwxAg6o2qmovgNkAJoabLCIiKoRJcD8XwD7b+yZrWbYvi0i1iPxVRM4PJHVEROSLSXB3Gj8te3CN5wCMUdV3A1gK4FHHDYncICJVIlLV2trqLaVERGTMJLg3AbCXxM8D0GxfQVWPqGqP9fYhAO9z2pCqzlDVClWtGD16tJ/0EhGRAZPgXglgrIhcJCIjAUwCMN++goi81fZ2AoDa4JJIRERe5W0to6opEZkMYDGAEQBmqeo2EZkGoEpV5wP4gYhMAJACcBTAdSGmmShSHPCX4iBvcAcAVV0EYFHWsqm21zcCuDHYpBGVljKYvIcShD1UiYgSiMGdiMpYcivZGNyJqOyUQxUbgzsRUQIxuBMRJRCDOxFRAjG4ExElEIM7EVECMbgTESUQgzsRUQIxuBMRJRCDOxFRAjG4ExElEIM7kUea3OFIKEEY3IkMSTkMSEKJweBORJRADO5ERAnE4E5ElEAM7kRECcTgTkSUQAzuREQJxOBORJRADO5EVLaS3CGNwZ2Iyo6UQY80o+AuIuNFpE5EGkRkSo71viIiKiIVwSWRiIi8yhvcRWQEgOkArgQwDsA1IjLOYb2zAPwAwNqgE0lERN6YlNwvA9Cgqo2q2gtgNoCJDuvdBuAuAN0Bpo+IiHwwCe7nAthne99kLRskIpcCOF9VFwSYNqISleCncJQYJsHd6cnD4NEtIqcB+B2AH+fdkMgNIlIlIlWtra3mqSQqAeJ4KhCVJpPg3gTgfNv78wA0296fBeBfALwsIrsBXA5gvtNDVVWdoaoVqloxevRo/6kmIqKcTIJ7JYCxInKRiIwEMAnA/MyHqtquqqNUdYyqjgGwBsAEVa0KJcVERJRX3uCuqikAkwEsBlALYI6qbhORaSIyIewEEhGRd6ebrKSqiwAsylo21WXdjxWeLCIiKgR7qBIRJRCDOxFRAjG4ExElEIM7EVECMbgTESUQgzsRUQIxuBMRJRCDOxFRAjG4ExElEIM7EVECMbgTUdlK8sj8DO5EVHbKYWR+BnciogRicCciSiAGd6IA9Q8oPnTHMszf3Jx/ZaIQMbgTBehkbwrN7d24+W9bok4KlTkGdyKiBGJwJyJKIAZ3IqIEYnAnCkGSO8dQPDC4EwWo2J1jbpm7FWOmLCzyt1IcMLgTxdhja/ZEnQQqUQzuREQJxOBO5JGyQp1iwCi4i8h4EakTkQYRmeLw+XdFZIuIbBKRlSIyLvikEkVLPFSoK68AFLG8wV1ERgCYDuBKAOMAXOMQvJ9Q1Xep6iUA7gJwT+ApJYoB8XIFIAqRScn9MgANqtqoqr0AZgOYaF9BVTtsb88EW4IREUXqdIN1zgWwz/a+CcAHslcSke8D+BGAkQA+4bQhEbkBwA0AcMEFF3hNKxERGTIpuTvdZw4rmavqdFW9GMD/APiZ04ZUdYaqVqhqxejRo72llIiIjJkE9yYA59venwcg13imswF8sZBEEcUd6yUpaibBvRLAWBG5SERGApgEYL59BREZa3v7OQD1wSWRKD74OJVKRd7grqopAJMBLAZQC2COqm4TkWkiMsFabbKIbBORTUjXu18bWoqJKBH2He3EzJW7Ik1DklusmjxQhaouArAoa9lU2+sfBpwuIkq4b85ciz1HOnHVpefinDNHFvW7y6HFKnuoEoUgySXCoBzvTgFgh6+wMLgTBagcSoQUDwzuREQJxOBOVIKa2jpRd/B41MkoClbKhMPogSoRFde//no5AGD3nZ+LOCXhYQ1WuFhyJ/LI5PmfsjxKEWNwJzJkL2lu3NuGituXoL2zL2sdlkepNDC4E/lw77J6HD7Ri/V7j0adlNhjS8hwMLgTUSTYbDRcDO5ERAnE4E4UgnKtajjZk8LJnlTUySCwKSRRoMq9quGdP18MwFsTTrYsCgdL7kQUkTK/EoaMwZ3yWll/GJf/ahm6evujTgoRGWJwp7x+tagWBzu6sbP1RNRJISJDDO5EIWAtsgf8sULB4E5EkSj3h89hY3AnIkogBnciIo8WVDfj4799GQMDpVunxHbuFEt9/QMAgNeNKH75xKRdNmsczEUZHv22sf/vp6vR1deP7lQ//m5kaYZRltwplt7/y6V4960vFvU7vdQRl255rnREeQHMjN7Zl1KkrIJC0jC4Uywd6+xDV1/07e7LdZiBpPjC/Svxmd+9GnUyQsHgTuSDsKlHYjQePhl1EkJhFNxFZLyI1IlIg4hMcfj8RyJSIyLVIrJMRC4MPqlE8XWiJ4WHVzRCWdQfJkk/ydrGI5i5clfUyQBgENxFZASA6QCuBDAOwDUiMi5rtY0AKlT13QD+CuCuoBNKFCtZAeu252pw+8JaLK9riSY9Ifn0Pa/g+j9V+vrbJN78XD1jDW5bUBN1MgCYldwvA9Cgqo2q2gtgNoCJ9hVUdbmqdlpv1wA4L9hkEsVbe1d6Or6evmQ9vKtvOYFl25N1wUoKk+B+LoB9tvdN1jI31wN4vpBEESVVgmogjDW0nMDDKxqjTkbZMWmg6XTz5HiMisg3AVQA+DeXz28AcAMAXHDBBYZJJIq/JFZBmLrqgVU43p3CdR8ag9Md+iVwPPdwmJTcmwCcb3t/HoDm7JVE5FMAbgYwQVV7nDakqjNUtUJVK0aPHu0nvUQlLUkPB4OSmZkpu4WRsKtXqEyCeyWAsSJykYiMBDAJwHz7CiJyKYAHkQ7srICjsjW7ci8AoNelY0w5B3+2FCquvMFdVVMAJgNYDKAWwBxV3SYi00RkgrXabwC8AcDTIrJJROa7bI4o0ZbWHnJcXs7VMm59AlgdEy6jQRFUdRGARVnLptpefyrgdBElCgut8dFt9Xx+/etGRJySwrCHKhEVRfb1rVTr3N9xywv44B3Lok5GwRjciQwVUvou62qZqBPgQ1tnn9F6pXxHxuBOvjQf64o6CSWpVEujFKw4XKwZ3H3o6u3HMpcHZ+Xi6hlrAACp/hIuugQsiBO6FB8iHmjvwpETjq2XA+VWyi3l0m+cMbj7cMu8rbj+0SrUNHdEnZRYuW9ZPeZt2h91MiJRyiX6D97xEt53+9LQtu92UYxD6TfOSnMKkRK350h6iNATVucMMnP3kh0AgImX5Bq9It7sAeuVHa3457eehbec9froEkSR23e0E/0DijGjzizq97LkXgB2yqBcrp21Dl/739eGLCvnQ6YUq6TCtnx7Cz5y13J87LcvF/27Gdx9KOVbbApOV28/nlnfVNBFfPeRzvwrJZzT+fJvv1mOA+3dAJI9mFqUw/8yuBO5mLagBj9+ejPWNB6NOimJYL9G7on4ohdFfX9Ncwfmbx42LFdoGNwL4FbiOHyiB9+auRZtJ3uLmh4KVktHumR5MohnK+V8s1fOebf57L0r8IMnNxbt+xjc/chzsM5cuQsr6g/jiXV7i5MeoiJRVazeebjsnzfFIfsM7gWIww6mwgW5mzPbUlWsaTwSuyD55Lp9+PpDa/Fc9YHAthnWb3DkRA/2HQ23+sdevZMZk6ZUMLj7kO8us5jn6+qdh/H9v2yILEiUYwsIP7KPmbmb9mPSjDV4ZkO82v3vOZpuBry/zbyHclS1MpffsQwfuWt5KNvucgjkN/1tSyjf5ReDewHyBbZiPLS5blYlFm454Dp+OBXOy250G942W+aB4t6QS5blrC+k3tMr6lsdl2/Y2xbK9/nF4O4De9ZRYGJWLVOIpGS17uDxqJNghME9JmoPdGDMlIXYtO+Y4+dJOXHKRan3lVBV/N/HqvDKDudSqpfquHyFIR674WBwN3T0ZC8eXtE4tG7bbSAkwwN/eV0LxkxZiIaWE3nXfWl7evbCxdsODv2gtGNEIuUKRknZHQMKLN52CN9+ZN2Q5faLkulzniQHb3veTKvkioVjyxj68ZxNWF7Xioox5xiXuvKtt9BqcbBhbxv+8S1vMNpmkk+UUue0P73uj+yAGOfdWcwOOeQdS+6GOrrTHVlStgeXriem1zPWYH3XkfU8flWpUFXc+LctJfcQyonT7nH73d12ZXapLspC3n3L6gPZTutxs2GCS6xAWzYY3H0I6mD1sxm3Kp+4lei7+vrx5Lq9+MZDa6NOSqSi2G+Z0TkLMXvdPs9/k5Rms6VW/eKGwT0iqxoO4+n1TQDMDnq3Kp5iHGepgfTdSpOHts2mknLCZ7jtjuzlW/a3h52UUGSONy9NOIN6ePzC1oM41lm6Q3qUWshncC9AvlJXrsA7c+WuYNMSYpDccSj9wPfmZ4PrpFHqrUWC5BSQltSkZ/JK2sUtLC0d3fju4+vxvcc3RJ2U2By5DO4hMDld7QeIp1vzrHXjHiTjVp2US6p/AMe6hk+sHFZnmrgpZF/3pNJ3j6XQ6SsmtTIM7mHKdQzYDxCji0FMDihTmfwkKez9bO5WbHboh5C0fedVvvx/5K7l6OgeflEM0smeFDp7U9h/rAvtDhfgQJTYfjYK7iIyXkTqRKRBRKY4fP5REdkgIikR+UrwySwdCvOTVQHMqdyHD9/5ksOn/o4Et2AYpxJw87Hg6+5LwXM+mgbGab8B4cWvjXudO+cNfm+BX/zOny/GJb9Ygg/f+RI+dc8r6B/w/8OXWAx3lTe4i8gIANMBXAlgHIBrRGRc1mp7AVwH4ImgE1gKpj1Xg/V7cjfZ29bcji/ctxKdvUPH/v7pM9XY7xDMhpTcTZpCui33caR94u6X8fEIpv3K6LOPgxOz4OaHSRXclqZ2PLZmT1HS42bWyl3YcSi8rvW5dnWm/f/9L9VjzJSFedfzIzP+UuvxHgzE7arqg0nJ/TIADaraqKq9AGYDmGhfQVV3q2o1gESOXjVrlfPDT/vDsDsWbceW/e1DLgK54u5ptg9venbLsLk23fT1D2Bh9QHXzjBff2gNrsvqVZitsfUkdh0+afR9dkFVL6jaq2W8n2TtneHewnsxdd5Wo/XcfrtM7r9w/0rcMtdsW2GZtqAGn793Zc51/IREk8Mms93fvujcTDPT/LC5vXvIxPSp/gHMqdyHAaskftuCGlzxu1d9pNIlXap4ua7F6KJSaiV6k+B+LgB7o9Yma5lnInKDiFSJSFVrq/OYFXHg9BAzUxJQdS9d1B7owBenr0Jnb2rYNtbtzj2VWyY4PLJqN77/xAa8sPWglZahVu88gpfrwvltgyzs+H0QvLP1BN4z7cXgEpKDW0Du6O7DMms4iGZrHtCk6O0fQFdvPy6+aVHUSRnCviuu/1Pl4OtZq3bhp89U46mqdIiauXIX6gK8+3h2435c90glnrS1609SO3ennPg6zVV1hqpWqGrF6NGj/WyipGSCXXp2miPp17bPs4+BXy6sxaZ9x7B+T1vBpeAjIU7h19Xbj3W7zOYNPdRh1kvRbk3jEWy0eqZ6vWDsah16x9FyvBtjpizEbGvWq288vAbvvnWx5zTls7yuBX1We//F2w55+lt7MIhD08e2HG3JCzlsc5Z+Pfws9rvjzHlwLKS7uczzof3H0q10Zq7chVddB1MrLSZjyzQBON/2/jwAZT2oRHZg9vNsxmtwL6TJ4/aDHRj1hjMw6g1nGK0/5W/VmLepGSt++nGcf87f+f5e9+2fai+vSJ+sZ54xAu/4hzd63tbuw+mT7pkNTbjkgjdhVcMRx/UWVDejrbMPq+oP4yNvH4VvfOBC4+9YvfMwHlm1G6PPMvv9ssWjnHdK0EHKpKSrUGz107HLltiUhzkN/Ja+b1tQ42n9Rh/Vn0ExKblXAhgrIheJyEgAkwDMDzdZ8eB0EpjUzakW3j5dka7mOdnbn/d7x/9+BT559yvG295+IH1bezLr4XAYd6P9A4ov/3E1xv9+ha+/t+c71zYmP7ERt8zdihe2HcTNz3qr2z58Il06dBtLZUV9Ky7/1TJ0p/IHF6/7/XuPr/e0/jPrmwoer8f+m4YxxaCbz983vL7/4RWN2He00+jY6wxxmju302vInXpo3+5P3uCuqikAkwEsBlALYI6qbhORaSIyAQBE5P0i0gTgqwAeFJFtYSa61AxpDQH3A8F+gHouuWetf+BYF678g3lADK1tb5Fl/w6vWrPihNmZK9+Wf7mwFgc7uo2a12VXy+QrCzy/9WDuFbL8+OnN+NIDqz39TdiMHqhq9ntFS0c3bl9Yi2sfWRdZZ7241K87MWrnrqqLVPXtqnqxqv7SWjZVVedbrytV9TxVPVNV36yq7wwz0aVurVVfnesusdCD5oGXd3r+mx88udHT+nFoLbbbmq4uzHM/364y2ZeFJu8rf1yNGz3M0WlvUeKV235/ua4FLYYjQRb6naqnqjtP9qTydvoLOwbH4FQYhj1U88hV3ZH5bMgaempQqMMnnE8ERfCxyOTgMx1/u1QKKxv2tmF5XcuQZcPSZmXcrcpk+faWnO2mg5Dv58rVp8HkAetTlXtRtacNT67bi/auPqO65YXVwT8Wu+6RSvzVGuzOj6AKC/0DWvBUd27nZiFKrZTP4J7H/3tq07BluXaiaWuI1xqHP/jrSfUP6wRVzr70wGp8+5HKnOtkfm+3dvtzN+13XD4woMYdYrwEb+e/F08nfnap+3+eOVVif88vXhzyQDrjeLdZ0I+EQdaz90T2++xNXPH7dFv2zU3pnq3p51jmwmpdU0oY3POYu8m9BJQvNLiN/HjtrHWOJc0r/7AC46Y6N+PL1zQxiFLRPUt24J9veaHwDRVRrnyv33MU81z239tuWmRczZEvMHstsOWrMrn/pYacn8/dOPyC9a5bX8SPn97sLSEuSqE6zvTCu6YxfV6EXShyfY4W6rcWhsHdh1w7NOf8mnmiQGOre7OpF2u8ta32495l9eiytTgohZM8W/aDtVzdyK9+cE3Obc2uPNUx5URPCivrD7t8Z26n5dmv9rs5VeC+l+rtHw7jtwTudiHzKrS2+LmauecdPzvYpJgqsZoWTxjcE6LSsNORm0LG7IhSrrpXLzn60VOb8M2Za30NamZy/mfuvF7Z0Yq+VDx/a79Mfp9HX9s95L3XX6gUxooptesAg7tHQ46h6I+nQd/5c1VBf3+w41Q3+j1H3MbMLrXD19ZaxoGXC1Z9S3pCki6nttKFVroDg4PHvVzXMmR4Wz+HUGpA8YFfLcVL2wu7m8s3SBeQO+tHDXtJm+RxbePQwkn2rov7vAVRYHD34VDH0PFEhnT6cDmSBwbUtdtyKbCn2zHAIT2mysU3LcKK+uLn4/2/XIr33bbE09+YBBWTAJUvsOQLO/bftqM7VVCLk4xDHT24bUGt0bpVu4+ioWX4HY7bKJSm18RcI0juc5hUI1Pdc9BhPJ7skre9auhQRw+OnMzduqUECu4lx2T4Acqy3aoKaG4ffgvvtAwAXtre4ri8VJjULfZaPTDzPfALQ+YBdHWTWRf1oyd7jU74ts5enHPmyEKSVlC9bCHVYaZ/+xXDEUe9f7/7Z91WAaG9q2/IxW/drqP42oNm6ak92DH4esozuR9+hx3bjeY5LrGbC5bcCzAwoLhl7tbB5lgAMHWec+fcHoOu6XERdm/Xqx98DfNcmjC+vMPsImk6FG/mYWgmUPo5P7fkueCEFXgK3a7bHUkQ6VUAy2oP4T2/eBEd3emWLKrpITOcZHfuVQUWVh8YfL/JYYar7PUL8fWHnB++57trmzpvW+j9KPxicC9AZ28/HluzB9fMWBt1UgrmdBC7lVa2Zz3EDHpG+rW7juKHs4f3LwDyz9iTYXoxPS0r2xPuXwUAmLdpP5bWpi8k+R7WpQqY1eehFbuwO6uNvunWCg1ormPMB1DHMaA62FPbz7Z3tp4Ytm9yUWhBnYgyo7p69cyGwqvYwsLg7lHL8eH1hXEYxtXJAlsvRrceniYumbYEPanwBm3yw3QatRe2HsTkJzYMvs+0QbdfXJ51aFcepP/0+TC8mJNFmwTlXtsF1a1Tkel18Ncv1OVtYmr34CuN+JefBzvU85gpCweHpo7jKc7g7tHkJ06NzzI4m1AJ7viHVzQ6LrfPYmTPy5IabwNUZevNKilv3NvmbwjXgJg+47jj+e1YYLv9D0O+kn+mpU5Gsapu3b7HzyxdwNDhLVSBmqwqGIWXu5LCSuLZ2/Ir07/k2Y37Pc0A1j+grlWLxcLgXoBMVYZJG1u/x2n/gOIXz3kfZPMPS+sdl7vOYlTgiZRdIrvqgdWOQ7iWo0dX7446CZ78bumpqe4yu9XpEM9elN35akVWp7Duvn7jQLv/WBfqA5pR6RbD5y8tHe6zarUc78F/PeU+8F52vr7+0BrXqsViYXAPQAFVrnllJorwyjRJzce68MJW55KrpwJPjnVP9qRwu8dJDorNXi21JODewE7NAkuZ34Ku/Txwqqq8+VnzUS0bW0+iKs+k9AOGJ97ja/YarffVPK14cs06lp0Up+cNxcamkAUIu659/uZmz8P02m3c2zY416qbLz2wGgc7uvHDT471/T1A+u5l7sb9aGg5gZ9c8U9DPvvZ3K0F1VtPey78C0Nm0hPAfx24m0KG3y3E+j1trq1TAPfhMJxipsmRbr+DdbpA1B44jg9dPMpgS2Z+v8z57jT9/d7PzT1HOn31UAbSd9ilVj1bdsF93a6jqLjwbJzm5VF8RJ5Y69zJxMSJnhSuMpi0IdMztdAWEpfaOhhlB3fTwH6ooxt//8bXD1s+a5XzAGxxkWl1U2xf/qO/STuyO+X1pgZOPVh00ZsaMDqGghwm4N4cwd0vP1WgQDpfpTAEgl1ZVcusqG/F1x58DTNcHjZ65aVLtHuXfme3L6gZHPHO1PFu/+3P73XomFS1+yg+62G2JydeLhof+NWygr4rKfb7LD3a5Rt7bE7VPuPv+cnTm3H1jOHtwO379tpZ64a0UHLa7Qc7ujGnat/wD0Kw49CJ/Cs5yNVCJ3vaSTvV0mtYUVbB/YDV7bmhxd+Oz+blSv3rF7Ybr/vbxXV42GW44Fz+stasbtHUrc/VDGvx4NVFNy4KKDXlw+vUek5uylO//dO/Vrt+lt2PwW2Sl+V1p4aheK3xSN46dwDYmWPk0yBlxnv3Kldwz1VA69fSaxAdu+B+rLMXS30+8MrsuKBun+543jxge3H/cn/d++8MKT3FNOH+8m5hc6lba6YYOGl7tpDdUiYuCmnVZtq3olhiF9y/9/gGfOfPVb6myTqthNulU5rp2DFJ1RbjGYLuXnKqCeVvFtdFmBL/vHScslNV405lpq18ChW74L7nSPq2buv+ds+dLewl923N7RgzZSHWOkx3B6THsni6SPWDSVPdZDZEAFGp6fdZ8vNSan/bTYuKUsqPXWuZTCuX66y5NXff+Tmjv9u879hgr8UBBVY1pG8bl9Yewgfe9uZh639x+qogkluWMuOzEMXNQp+9lU3b0mf09Q9gxGkjfH2XqdiV3EfkaMKY6h/AY2v2OE5TNnH6qsEHQwMDOvjwx6mtr9PY10REbuy9ek0UYwhwo+AuIuNFpE5EGkRkisPnZ4jIU9bna0VkTNAJzciuEzve3YdFWw6g5Xg3vvv4etwyd+vgxNSqil2HTw67Bero7husd5/xauNgt+hMXdin7vH3pJ2IyEQhA/WZylstIyIjAEwH8GkATQAqRWS+qtq7DV4PoE1V/1FEJgH4NYCrw0hwdsH9XbcOb12wad8xzN/cjBe3HcSC6gO49II3Dfl8Rf1h1DSfauL3jlteGHx96xfGBZtgIqIshQwTbcqk5H4ZgAZVbVTVXgCzAUzMWmcigEet138F8EkJaki3LCZPs5/fehA/eHKu7BLmAAAFVklEQVTj4Gh/TmOAH3GZXu3WInR1J6LyNt1nc2cvTIL7uQDszUaarGWO66hqCkA7gOFPKQOQq86diCgOTCcXL4RJcHeKptn3FCbrQERuEJEqEalqbfU3yfI3Lr/Q198REZWKu7/6ntC/w6QpZBOA823vzwOQ3R85s06TiJwO4P8AGDYwiqrOADADACoqKnxVOn3r8gvxLQZ4IqKcTErulQDGishFIjISwCQA87PWmQ/gWuv1VwC8pEFMxEhERL7kLbmrakpEJgNYDGAEgFmquk1EpgGoUtX5AGYCeExEGpAusU8KM9FERJSbUQ9VVV0EYFHWsqm2190Avhps0oiIyK/Y9VAlIqL8GNyJiBKIwZ2IKIEY3ImIEojBnYgogSSq5ugi0gpgj88/HwUgnvN4eVMO+WQek6Ec8giURj4vVNXR+VaKLLgXQkSqVLUi6nSErRzyyTwmQznkEYhXPlktQ0SUQAzuREQJFNfgPiPqBBRJOeSTeUyGcsgjEKN8xrLOnYiIcotryZ2IiHKIXXDPN1l3qROR3SKyRUQ2iUiVtewcEVkiIvXW/2dby0VE7rXyWi0i77Vt51pr/XoRudbt+4pBRGaJSIuIbLUtCyxPIvI+6zdrsP626NNxueTxVhHZb+3LTSLyWdtnN1rprRORK2zLHY9fa0jttVben7KG1y4qETlfRJaLSK2IbBORH1rLk7Yv3fKZqP0JVY3NP6SHHN4J4G0ARgLYDGBc1OnymIfdAEZlLbsLwBTr9RQAv7ZefxbA80jPdHU5gLXW8nMANFr/n229PjvCPH0UwHsBbA0jTwDWAfig9TfPA7iyRPJ4K4CfOKw7zjo2zwBwkXXMjsh1/AKYA2CS9fp/AXwvgjy+FcB7rddnAdhh5SVp+9Itn4nan3EruZtM1h1H9gnGHwXwRdvyP2vaGgBvEpG3ArgCwBJVPaqqbQCWABhf7ERnqOqrGD7zViB5sj57o6q+pukz5c+2bRWNSx7dTAQwW1V7VHUXgAakj13H49cqvX4C6cnlgaG/V9Go6gFV3WC9Pg6gFun5kZO2L93y6SaW+zNuwd1ksu5SpwBeFJH1InKDtezvVfUAkD7wALzFWu6W3zj8DkHl6VzrdfbyUjHZqpKYlamugPc8vhnAMU1PLm9fHhkRGQPgUgBrkeB9mZVPIEH7M27B3Wgi7hL3YVV9L4ArAXxfRD6aY123/Mb5d/Cap1LO6x8BXAzgEgAHANxtLY91HkXkDQCeAfBfqtqRa1WHZXHOZ6L2Z9yCu8lk3SVNVZut/1sAPIv0rd0h65YV1v8t1upu+Y3D7xBUnpqs19nLI6eqh1S1X1UHADyE9L4EvOfxMNJVGqdnLS86EXkd0gHvL6r6N2tx4valUz6Ttj/jFtxNJusuWSJypoiclXkN4DMAtmLoBOPXAphnvZ4P4N+tVgmXA2i3bosXA/iMiJxt3Tp+xlpWSgLJk/XZcRG53KrL/HfbtiKVCXiWq5Del0A6j5NE5AwRuQjAWKQfJDoev1b983KkJ5cHhv5eRWP9vjMB1KrqPbaPErUv3fKZtP1Z1Ke3QfxD+gn9DqSfUt8cdXo8pv1tSD9R3wxgWyb9SNfRLQNQb/1/jrVcAEy38roFQIVtW/+B9IOdBgDfjjhfTyJ9G9uHdGnm+iDzBKAC6RNtJ4D7YXW+K4E8PmbloRrpAPBW2/o3W+mtg61FiNvxax0b66y8Pw3gjAjy+K9IVx9UA9hk/ftsAvelWz4TtT/ZQ5WIKIHiVi1DREQGGNyJiBKIwZ2IKIEY3ImIEojBnYgogRjciYgSiMGdiCiBGNyJiBLo/wOjKVH1+iz6DQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(clf.components_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43.71292605795277"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.reconstruction_err_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NMF in summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Benefits: Fast and easy to use!\n",
    "\n",
    "Downsides: took years of research and expertise to create"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes:\n",
    "- For NMF, matrix needs to be at least as tall as it is wide, or we get an error with fit_transform\n",
    "- Can use df_min in CountVectorizer to only look at words that were in at least k of the split texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Truncated SVD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We saved a lot of time when we calculated NMF by only calculating the subset of columns we were interested in. Is there a way to get this benefit with SVD? Yes there is! It's called truncated SVD.  We are just interested in the vectors corresponding to the **largest** singular values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/svd_fb.png\" alt=\"\" style=\"width: 80%\"/>\n",
    "\n",
    "(source: [Facebook Research: Fast Randomized SVD](https://research.fb.com/fast-randomized-svd/))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shortcomings of classical algorithms for decomposition:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Matrices are \"stupendously big\"\n",
    "- Data are often **missing or inaccurate**.  Why spend extra computational resources when imprecision of input limits precision of the output?\n",
    "- **Data transfer** now plays a major role in time of algorithms.  Techniques the require fewer passes over the data may be substantially faster, even if they require more flops (flops = floating point operations).\n",
    "- Important to take advantage of **GPUs**.\n",
    "\n",
    "(source: [Halko](https://arxiv.org/abs/0909.4061))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Advantages of randomized algorithms:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- inherently stable\n",
    "- performance guarantees do not depend on subtle spectral properties\n",
    "- needed matrix-vector products can be done in parallel\n",
    "\n",
    "(source: [Halko](https://arxiv.org/abs/0909.4061))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Timing comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 35.8 s, sys: 1.37 s, total: 37.2 s\n",
      "Wall time: 11.3 s\n"
     ]
    }
   ],
   "source": [
    "#1. Nupmpy's linear algebra SVD\n",
    "%time u, s, v = np.linalg.svd(vectors, full_matrices=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.2 s, sys: 2.23 s, total: 13.4 s\n",
      "Wall time: 4.41 s\n"
     ]
    }
   ],
   "source": [
    "from sklearn import decomposition\n",
    "\n",
    "#2. sklearns randomised SVD\n",
    "%time u, s, v = decomposition.randomized_svd(vectors, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.99 s, sys: 773 ms, total: 4.76 s\n",
      "Wall time: 1.58 s\n"
     ]
    }
   ],
   "source": [
    "import fbpca\n",
    "\n",
    "#3. Facebooks randomised SVD (PCA)\n",
    "%time u, s, v = fbpca.pca(vectors, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more on randomized SVD, check out my [PyBay 2017 talk](https://www.youtube.com/watch?v=7i6kBz1kZ-A&list=PLtmWHNX-gukLQlMvtRJ19s7-8MrnRV6h6&index=7).\n",
    "\n",
    "For significantly more on randomized SVD, check out the [Computational Linear Algebra course](https://github.com/fastai/numerical-linear-algebra).\n",
    "\n",
    "In the Computational Linear Algebra course (and repo) there are instructions for how to convert the decomposed  matrices in this notebook to .csv files that can be viewed in .numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
